# -Big-Data-and-Cloud-Computing-course-Project
In this project our problem is “why Al-Rajhi bank customers leave and go to other banks?” so we looked for negative hashtags in twitter that people were talking about Al-Rajhi bank badly, to search about the reasons which made them leave. 
# Library that we used:

**GetOldTweets3:**

GetOldTweets3 is an improvement fork of the original Jefferson Henrique's
GetOldTweets-python. It fixes known issues and adds features such as counting
retweets, searching over multiple user’s accounts, etc.

**Nltk(Natural Language Toolkit):**

NLTK is a powerful Python package that provides a set of diverse natural
languages algorithms. It is free, opensource, easy to use, large community, and
well documented. NLTK consists of the most common algorithms such as
tokenizing, part-of-speech tagging, stemming, sentiment analysis, topic
segmentation. We have used NLTK to help the computer to analysis, preprocess,
and understand the written text the we extracted from twitter.

**Pandas:**

Pandas is a library created to help developers work with "labeled" and "relational"
data intuitively. It's based on two main data structures: "Series" (one-dimensional,
like a list of items) and "Data Frames" (two-dimensional, like a table with multiple
columns). Pandas allows converting data structures to DataFrame objects, handling
missing data, and adding/deleting columns from DataFrame, imputing missing
files, and plotting data with histogram or plot box. It’s a must-have for data
wrangling, manipulation, and visualization. We have used panda for cleaning our
data.

**Numpy:**

The library offers many handy features performing operations on n-arrays and
matrices in Python. It helps to process arrays that store values of the same data
type and makes performing math operations on arrays (and their vectorization)
easier. In fact, the vectorization of mathematical operations on the NumPy array
type increases performance and accelerates the execution time. We have used


NumPy for cleaning our data by specifying some texts, such as tweet that involves
Advertisements so we can delete it also we have used it to specify null value tweets
for deleting it etc.

# The tool that we used:

**Tweepy:**

Tweepy is an open-sourced Python library to communicate with Twitter and
access the Twitter API. It is great for simple automation and creating twitter bots.
And we have used the tool to Get tweets from our timeline, for analyzing them. We
have used it to extract tweets from Twitter.

**Mazajak:**

An Online Arabic Sentiment Analyzer, Sentiment analysis is one of the most
useful natural language processing applications. There are many papers and
systems addressing this task, but most of the work is focused on English. We have
used it to classification our data.

